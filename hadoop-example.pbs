# !/bin/bash
# Hadoop HPCC Cluster Test Job
#PBS -k eo
#PBS -j eo
#PBS -l walltime=00:20:00
#PBS -l nodes=3:ppn=6
#PBS -l pmem=2g

# setup your own hadoop path
WORK_HOME=/path/to/your/working/dir
# setup hadoop home for running hadoop example
HADOOP_HOME=/path/to/hadoop-2.6.0/home/dir

echo $(date) - HADOOP PBS Job Started

source $WORK_HOME/setup.sh

# This starts the job and task trackers
$WORK_HOME/setup-and-start-hadoop-on-hpcc

# Check to make sure hadoop started up before running our code.
if [ $? -eq 0 ]; then
  # start the pi estimation job
  cd $WORK_HOME
  
  hadoop dfs -mkdir -p /user/hduser/wordcount
  hadoop dfs -copyFromLocal pg20417.txt /user/hduser/wordcount/pg20417.txt
  hadoop dfs -ls /user/hduser/wordcount
  hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar wordcount /user/hduser/wordcount /user/hduser/wordcount-output
  # hadoop dfs -cat /user/hduser/wordcount-output/part-r-00000
  # hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar pi 250 1000

  # when this script exits the hadoop cluster is shutdown so copy off data here
  hadoop dfs -copyToLocal /user/hduser/wordcount-output/part-r-00000 ./
fi

echo $(date) - HADOOP PBS Job Finished

